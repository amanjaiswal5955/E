{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Identifying Potential Fraudulent Activities:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To detect potential fraudulent activities, we can use an unsupervised machine learning technique called Isolation Forest or One-Class SVM. These algorithms are effective in identifying anomalies in a dataset without the need for labeled examples of fraud.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example code using Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the financial transactions dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('G:\\Placement\\Stepchange Assignment/financial_anomaly_data.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select relevant features for anomaly detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Timestamp', 'TransactionID', 'AccountID','Merchant','Amount', 'TransactionType','Location' ]\n",
    "X = data[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Null value data (Cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X =X.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run Isolation forest model for all the data, memory requirement is too high that's why i considered 30% sample data to identify potential fradulent activities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X.sample(frac=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize and fit the Isolation Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'transactions' with relevant columns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Select relevant features for anomaly detection\n",
    "features = ['Amount', 'TransactionType', 'AccountID', 'Timestamp', 'Location', 'Merchant']\n",
    "\n",
    "# Perform one-hot encoding for categorical variables\n",
    "transactions_encoded = pd.get_dummies(data[features])\n",
    "\n",
    "# Initialize and fit the Isolation Forest model\n",
    "model = IsolationForest(contamination=0.01, max_samples= 'auto')  # Adjust contamination based on your dataset\n",
    "model.fit(transactions_encoded)\n",
    "\n",
    "# Predict anomalies\n",
    "data['IsAnomaly'] = model.predict(transactions_encoded)\n",
    "\n",
    "# Flag suspicious transactions\n",
    "suspicious_transactions = data[data['IsAnomaly']==-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(suspicious_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. I chose the Isolation Forest approach because it's effective for high-dimensional data, it's less sensitive to outliers, and it performs well on imbalanced datasets. Other methods i consider include One-Class SVM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Features to consider for fraud detection is include transaction amount, time of day, transaction type, location. i can improve my model by normalizing or scaling numerical features, encoding categorical variables, and creating new features like transaction frequency or average transaction amount.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Predicting Spend for Transaction Types in June:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for predicting spend using linear regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "# Assuming 'Timestamp' is the column containing timestamps in the DataFrame\n",
    "data['Timestamp'] = pd.to_datetime(data['Timestamp'], format='%d-%m-%Y %H:%M')\n",
    "# Filter data for February\n",
    "data = data[data['Timestamp'].dt.month == 6]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'TransactionType' is a categorical variable encoded numerically\n",
    "X_train = data[data['Timestamp'].dt.month == 6]['TransactionType']\n",
    "y_train = data[data['Timestamp'].dt.month == 6]['Amount']\n",
    "# Encode categorical variables if needed\n",
    "X_train_encoded = pd.get_dummies(X_train, columns=['TransactionType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict spend for June\n",
    "X_june = data[data['Month'] == 'June'][['TransactionType']]\n",
    "predicted_spend_june = model.predict(X_june)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  5. Testing Model Effectiveness:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the effectiveness of the model on unseen data, we can use a holdout validation set or perform k-fold cross-validation. Evaluate the model's performance using metrics like precision, recall, F1 score, and AUC-ROC. Additionally, consider monitoring the model's performance over time to ensure it adapts to changing patterns in fraudulentÂ activities."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
